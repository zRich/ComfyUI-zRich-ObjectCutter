import json
import numpy as np
from PIL import Image
import torch

class ZRichObjectCutter:
    """
    ğŸ§© ZRich Object Cutter
    å°†å›¾ç‰‡ä¸­çš„ç‰©ä½“ï¼ˆé€šè¿‡ MASK æˆ– bboxï¼‰æŠ å›¾ä¸ºä¸åŸå›¾åŒå°ºå¯¸çš„é€æ˜å›¾åƒã€‚
    ç°åœ¨æ”¯æŒç›´æ¥æ¥æ”¶ SAM2 çš„ MASK è¾“å‡ºï¼Œé€ä¸ªåŒºåŸŸç”Ÿæˆé€æ˜èƒŒæ™¯ RGBA å›¾ç‰‡ã€‚
    """

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                # ç›´æ¥æ¥æ”¶ Sam2Segmentation çš„è¾“å‡º MASK
                "mask": ("MASK",),
            },
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("images",)
    FUNCTION = "cut_objects"
    CATEGORY = "zRich/Segmentation"

    # åŸºäº MASK æŠ å›¾å¹¶è¿”å›é€æ˜ RGBA å›¾åƒï¼ˆå°ºå¯¸ä¸åŸå›¾ä¸€è‡´ï¼‰
    def cut_objects(self, image, mask):
        # è¾“å…¥ image: (B, H, W, C) æµ®ç‚¹ 0..1ï¼›mask: (..., H, W)
        img_np = image.detach().cpu().numpy().astype(np.float32)  # ä¿æŒ 0..1
        B, H, W, C = img_np.shape

        mask_np = mask.detach().cpu().numpy().astype(np.float32)

        # ç»Ÿä¸€ä¸º (N, H, W)ï¼šå°†é™¤æœ€åä¸¤ä¸ªç»´åº¦å¤–çš„æ‰€æœ‰å‰å¯¼ç»´åº¦å±•å¹³ä¸º N
        if mask_np.ndim == 2:
            masks_np = mask_np.reshape(1, H, W)
        elif mask_np.ndim >= 3:
            h, w = mask_np.shape[-2], mask_np.shape[-1]
            n = int(np.prod(mask_np.shape[:-2]))
            masks_np = mask_np.reshape(n, h, w)
        else:
            masks_np = np.zeros((0, H, W), dtype=np.float32)

        outputs = []
        # å§‹ç»ˆä½¿ç”¨ç¬¬ä¸€å¼ åŸå›¾è¿›è¡ŒæŠ å›¾ï¼›å¯¹æ¯ä¸ª mask è¾“å‡ºä¸€å¼ é€æ˜å›¾
        src = img_np[0]  # (H, W, C)
        for i in range(masks_np.shape[0]):
            m = masks_np[i]

            # äºŒå€¼åŒ–æ©ç å¹¶åšé€æ˜èƒŒæ™¯ï¼ˆæŒ‰ 0/1 é˜ˆå€¼ï¼‰
            alpha = (m > 0.5).astype(np.float32)
            rgb = src * alpha[..., None]
            rgba = np.concatenate([rgb, alpha[..., None]], axis=-1)

            outputs.append(torch.from_numpy(rgba).unsqueeze(0))  # (1, H, W, 4)

        if len(outputs) == 0:
            # å¦‚æœæ²¡æœ‰æ©ç ï¼Œè¾“å‡ºä¸€å¼ é€æ˜å›¾ï¼ˆä¸ç¬¬ä¸€å¼ åŸå›¾åŒå°ºå¯¸ï¼‰
            blank = np.zeros((H, W, 4), dtype=np.float32)
            return (torch.from_numpy(blank).unsqueeze(0),)

        result = torch.cat(outputs, dim=0)  # (N, H, W, 4)
        return (result,)
