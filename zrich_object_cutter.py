import json
import numpy as np
from PIL import Image
import torch

class ZRichObjectCutter:
    """
    ğŸ§© ZRich Object Cutter
    å°†å›¾ç‰‡ä¸­çš„ç‰©ä½“ï¼ˆé€šè¿‡ MASK æˆ– bboxï¼‰æŠ å›¾ä¸ºä¸åŸå›¾åŒå°ºå¯¸çš„é€æ˜å›¾åƒã€‚
    ç°åœ¨æ”¯æŒç›´æ¥æ¥æ”¶ SAM2 çš„ MASK è¾“å‡ºï¼Œé€ä¸ªåŒºåŸŸç”Ÿæˆé€æ˜èƒŒæ™¯ RGBA å›¾ç‰‡ã€‚
    """

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                # ç›´æ¥æ¥æ”¶ Sam2Segmentation çš„è¾“å‡º MASK
                "mask": ("MASK",),
            },
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("images",)
    FUNCTION = "cut_objects"
    CATEGORY = "zRich/Segmentation"

    # åŸºäº MASK æŠ å›¾å¹¶è¿”å›é€æ˜ RGBA å›¾åƒï¼ˆå°ºå¯¸ä¸åŸå›¾ä¸€è‡´ï¼‰
    def cut_objects(self, image, mask):
        # è¾“å…¥ image: (B, H, W, C) æµ®ç‚¹ 0..1ï¼›mask: (N, H, W) æˆ– (H, W)
        img_np = image.cpu().numpy().astype(np.float32)  # ä¿æŒ 0..1
        B, H, W, C = img_np.shape

        mask_np = mask.cpu().numpy()

        # ç»Ÿä¸€ä¸ºåˆ—è¡¨å½¢å¼çš„æ©ç 
        masks = []
        if mask_np.ndim == 2:
            masks = [mask_np]
        elif mask_np.ndim == 3:
            masks = [mask_np[i] for i in range(mask_np.shape[0])]
        else:
            masks = []

        outputs = []
        for i, m in enumerate(masks):
            # é€‰æ‹©å¯¹åº”å›¾åƒï¼›è‹¥ mask æ•°é‡ä¸å›¾åƒæ‰¹æ¬¡ä¸€è‡´åˆ™ä¸€ä¸€å¯¹åº”ï¼Œå¦åˆ™é»˜è®¤ä½¿ç”¨ç¬¬ 0 å¼ åŸå›¾
            if len(masks) == B:
                src = img_np[i]
            else:
                src = img_np[0]

            # äºŒå€¼åŒ–æ©ç å¹¶åšé€æ˜èƒŒæ™¯
            alpha = (m > 0.5).astype(np.float32)
            rgb = src * alpha[..., None]
            rgba = np.concatenate([rgb, alpha[..., None]], axis=-1)

            tensor_img = torch.from_numpy(rgba)[None,]
            outputs.append(tensor_img)

        if len(outputs) == 0:
            # å¦‚æœæ²¡æœ‰æ©ç ï¼Œè¾“å‡ºä¸€å¼ é€æ˜å›¾ï¼ˆä¸ç¬¬ä¸€å¼ åŸå›¾åŒå°ºå¯¸ï¼‰
            blank = np.zeros((H, W, 4), dtype=np.float32)
            return (torch.from_numpy(blank)[None,],)

        result = torch.cat(outputs, dim=0)
        return (result,)
